#!/usr/bin/env bash
set -o monitor -o errexit -o nounset -o xtrace

# Install NixOS on ZFS on root with mirrored drives.
#
# This is a modification of:
# https://openzfs.github.io/openzfs-docs/Getting%20Started/NixOS/Root%20on%20ZFS.html
#
# This is intended to be run from a booted NixOS minimal ISO image, as root.

SELF_FILE=$(realpath --no-symlinks "${BASH_SOURCE[0]}")
SELF_DIR=$(dirname "$SELF_FILE")
# This script is assumed to be located in .new-installs/ in the correct
# repository.
SELF_REPO=$(dirname "$SELF_DIR")

[[ $UID -eq 0 && $EUID -eq 0 && $USER == root ]]

case "${1:-}" in
    ("") ;;
    (--suspend-after-install) SUSPEND_AFTER_INSTALL=true ;;
    (*) exit 1 ;;
esac


# Definitions

# The host name of this installation.
INST_NAME=yoyo
# A reasonably-globally-unique random identifier suffix for the ZFS pool names.
# Useful because pool names must be unique when imported, and this allows
# importing multiple pools that have the same "boot" or "main" prefix.
while true; do
    INST_ID=$(dd if=/dev/urandom bs=1 count=100 2>/dev/null | tr -dc 'a-z0-9' | cut -c-6)
    read -p "Use INST_ID = $INST_ID ? "
    if [ yes == "$REPLY" ]; then
        break
    fi
done
[ ${#INST_ID} == 6 ]

DRIVES=(
    /dev/disk/by-id/nvme-Samsung_SSD_970_EVO_Plus_2TB_S59CNM0R706239E
    /dev/disk/by-id/nvme-Samsung_SSD_970_EVO_Plus_2TB_S59CNM0R706236Y
)
VDEV=mirror

declare -A PARTITION_TYPE_CODE=(
    # sgdisk will not accept 00000000-0000-0000-0000-000000000000 (nor 0, etc),
    # so instead use an unassigned random UUID to make the initially-unused
    # other partitions have an unknown type that nothing will misinterpret.
       [unused]=$(uuidgen --random)
    # The peculiar codes of `sgdisk --list-types`:
     [biosBoot]=ef02
       [efiSys]=ef00
      [zfsBoot]=be00
      [zfsRoot]=bf00
    [linuxSwap]=8200
)

declare -A PARTITION_NUMBER=(
    # This layout is designed to allow the non-essential swap and other
    # partitions to be destroyed so that the main partition could grow if ever
    # needed.
    [legacyBIOS]=1
           [EFI]=2
          [boot]=3
          [main]=4
          [swap]=5
    [other-boot]=6
    [other-main]=7
)
declare -A PARTITION_SIZE=(
    # In GiB.  These sizes are designed so that the non-resizable legacyBIOS,
    # EFI, and boot partitions are large enough to never be too small.
    # legacyBIOS will probably never be used and only needs to be large enough
    # for GRUB's 2nd stage.  EFI will only hold a handful of bootloaders.  boot
    # could hold many NixOS boot environments' kernels and initrds.  A single
    # swap partition is made large enough to be able to hibernate my 64 GiB of
    # RAM (if ZFS ever supports hibernation in the future); and my swap is not
    # mirrored but is striped and so the total swap space is double what is
    # given here.  other-boot and other-main are only to allow temporary
    # installations of another OS like Ubuntu for testing purposes.

   #[legacyBIOS]=fixed
           [EFI]=1
          [boot]=8
         #[main]=remaining
          [swap]=64
    [other-boot]=2
    [other-main]=20
)
declare -A PARTITION_TYPE_NAME=(
    [legacyBIOS]=biosBoot
           [EFI]=efiSys
          [boot]=zfsBoot
          [main]=zfsRoot
          [swap]=linuxSwap
    [other-boot]=unused
    [other-main]=unused
)
declare -A PARTITION_OPTS=(
    # sgdisk options:
    [legacyBIOS]="--set-alignment=1"
           [EFI]=""
          [boot]=""
          [main]=""
          [swap]=""
    [other-boot]=""
    [other-main]=""
)

# These are ordered so that partition allocation starts from the beginning for
# legacyBIOS, EFI, boot, then from the end for other-main, other-boot, swap, and
# then from the remaining space in the middle for main.
PARTITION_OP_ORDER=( legacyBIOS EFI boot other-main other-boot swap main )
declare -A PARTITION_EXTENT=(
    # The start:end of the sgdisk --new option:
    [legacyBIOS]=24K:+1000K
           [EFI]=1M:+${PARTITION_SIZE[EFI]}G
          [boot]=0:+${PARTITION_SIZE[boot]}G
    [other-main]=-${PARTITION_SIZE[other-main]}G:0
    [other-boot]=-${PARTITION_SIZE[other-boot]}G:0
          [swap]=-${PARTITION_SIZE[swap]}G:0
          [main]=0:0
)

# 4 KiB for my SSDs' actual physical sector size.
ZPOOL_ASHIFT=12

declare -A POOL_NAME=(
    [boot]=boot-$INST_ID
    [main]=main-$INST_ID
)

POOL_PROPS_COMMON=(
    -o ashift=$ZPOOL_ASHIFT
    # Auto trimming could maybe be bad for my SSDs.  Will instead have the OS do
    # `zpool trim` on a schedule.
    -o autotrim=off
)

# In GiB
TMP_DATASET_SIZE=256
VM_ZVOL_SIZE=64

# These are ordered so that parents are created first, as required.  Those with
# canmount=off exist only to support being able to inherit properties for all
# their children.

MAIN_DATASETS_ORDER=(
    $INST_NAME
    $INST_NAME/home
    $INST_NAME/nix
    $INST_NAME/srv
    $INST_NAME/state
    $INST_NAME/tmp
    $INST_NAME/usr
    $INST_NAME/usr/local
    $INST_NAME/var
    $INST_NAME/var/cache
    $INST_NAME/var/games
    $INST_NAME/var/lib
    $INST_NAME/var/local
    $INST_NAME/var/log
    $INST_NAME/var/tmp
)
declare -A MAIN_DATASETS=(
    [$INST_NAME]="          -o mountpoint=/"
    [$INST_NAME/home]="     -o devices=off -o setuid=off"
    # Disable atime for faster accesses to the Nix files
    [$INST_NAME/nix]="      -o atime=off"
    [$INST_NAME/srv]=""
    [$INST_NAME/state]=""
    [$INST_NAME/tmp]="      -o devices=off -o quota=${TMP_DATASET_SIZE}G"
    [$INST_NAME/usr]="      -o canmount=off"
    [$INST_NAME/usr/local]=""
    [$INST_NAME/var]="      -o canmount=off"
    [$INST_NAME/var/cache]=""
    [$INST_NAME/var/games]=""
    [$INST_NAME/var/lib]="-o acltype=posix"
    [$INST_NAME/var/local]=""
    # journald requires ACLs
    [$INST_NAME/var/log]="  -o compression=zstd -o acltype=posix"
    [$INST_NAME/var/tmp]="  -o devices=off -o quota=${TMP_DATASET_SIZE}G"
)

BOOT_DATASETS_ORDER=(
    $INST_NAME
)
declare -A BOOT_DATASETS=(
    [$INST_NAME]="          -o mountpoint=/boot"
)

EXTRA_DATASETS_ORDER=(
    $INST_NAME/omit
    $INST_NAME/omit/home
    VMs
    VMs/blkdev
)
declare -A EXTRA_DATASETS=(
    # Only used for things that users want to omit from backups.
    [$INST_NAME/omit]="     -o canmount=off -o mountpoint=/mnt/omit"
    [$INST_NAME/omit/home]="${MAIN_DATASETS[$INST_NAME/home]}"
    # Only used for VM drive images which can either be files which get
    # compressed or zvols which do not.
    [VMs]="-o mountpoint=/mnt/VMs -o compression=zstd \
           -o atime=off -o devices=off -o exec=off -o setuid=off \
           -o primarycache=metadata -o secondarycache=metadata"
    [VMs/blkdev]="-o canmount=off -o compression=off"
)
for I in {1..8}; do
    EXTRA_DATASETS_ORDER+=(VMs/blkdev/$I)
    EXTRA_DATASETS[VMs/blkdev/$I]="-V ${VM_ZVOL_SIZE}G -s -b $((2 ** ZPOOL_ASHIFT))"
done

# Which channel to use as the needed "nixos-unstable" name.
CHANNEL_NIXOS_UNSTABLE=https://nixos.org/channels/nixos-unstable

# The Oxalica Rust Overlay as a channel for the needed "oxalica-rust-overlay" name.
CHANNEL_OXALICA_RUST_OVERLAY=https://github.com/oxalica/rust-overlay/archive/master.tar.gz


# Functions

function wait-until-partitions
{
    # Wait for partitions' symlinks in /dev/disk/by-id/ to be either present or
    # absent, because otherwise there would be some race condition where the
    # zpool commands wouldn't see some of the changes to the new partitions yet
    # sometimes.

    local MODE=$1 STATE D P

    sleep 1
    partprobe ${DRIVES[@]}
    sleep 1

    while true; do
        for D in ${DRIVES[@]}; do
            for P in ${PARTITION_NUMBER[@]}
            do
                if [ -b $D-part$P ]; then
                    STATE=present
                else
                    STATE=absent
                fi
                if [ $STATE != $MODE ]; then
                    sleep 1
                    continue 3
                fi
            done
        done

        break
    done
}

function zap-discard-drives
{
    local D

    for D in ${DRIVES[@]}; do
        sgdisk --zap-all $D
        blkdiscard -v $D || echo "Proceeding without doing blkdiscard"
    done

    wait-until-partitions absent
}

function partition-drives
{
    local PART_NAME NUM TYPE EXTENT OPTS D

    for PART_NAME in ${PARTITION_OP_ORDER[@]}; do
        NUM=${PARTITION_NUMBER[$PART_NAME]}
        TYPE=${PARTITION_TYPE_CODE[${PARTITION_TYPE_NAME[$PART_NAME]}]}
        EXTENT=${PARTITION_EXTENT[$PART_NAME]}
        OPTS=${PARTITION_OPTS[$PART_NAME]}

        sgdisk $OPTS --new=$NUM:$EXTENT --typecode=$NUM:$TYPE --change-name=$NUM:$PART_NAME \
               ${DRIVES[0]}
    done

    # Shouldn't be necessary, given how the above works, but might as well to
    # express intent and guarantee these properties.
    sgdisk --sort ${DRIVES[0]}
    sgdisk --randomize-guids ${DRIVES[0]}

    for D in ${DRIVES[@]:1}; do
        sgdisk --replicate=$D ${DRIVES[0]}
        sgdisk --randomize-guids $D  # Other drives must not have same GUIDs.
    done

    wait-until-partitions present
}

function create-boot-pool
{
    # Install the file(s) for my custom "compatibility feature sets" for ZFS,
    # into the installer system, as needed for the next `zpool create` command
    # that references them.  (This is installed into the installee system
    # differently and automatically by my /etc/nixos/configuration.nix.)
    mkdir -p /etc/zfs/compatibility.d
    ln -s -f -t /etc/zfs/compatibility.d/ \
       "$SELF_REPO"/zfs/my-zfs-compatibility-feature-sets/share/zfs/compatibility.d/*

    # Only features supported by GRUB2
    zpool create -f \
          -o compatibility=my-grub2-corrected-minimal \
          ${POOL_PROPS_COMMON[@]} \
          -O canmount=off \
          -O mountpoint=none \
          -O compression=lz4 \
          -O devices=off \
          -O relatime=on \
          -O xattr=sa \
          -R /mnt \
          ${POOL_NAME[boot]} \
          $VDEV \
          $(for D in ${DRIVES[@]}; do
                printf "$D-part${PARTITION_NUMBER[boot]} ";
            done)
}

function create-main-pool
{
    # I choose to not enable compression across the entire main pool, because my
    # SSDs are huge and I don't want their 3 GB/sec speeds slowed down by
    # compression.  Sub datasets can easily enable compression where
    # appropriate.
    zpool create -f \
          ${POOL_PROPS_COMMON[@]} \
          -O canmount=off \
          -O mountpoint=none \
          -O dnodesize=auto \
          -O relatime=on \
          -O xattr=sa \
          -R /mnt \
          ${POOL_NAME[main]} \
          $VDEV \
          $(for D in ${DRIVES[@]}; do
                printf "$D-part${PARTITION_NUMBER[main]} ";
            done)
}

function create-sub-datasets
{
    local POOL=$1
    local -n DATASETS=$2 DATASETS_ORDER=$2_ORDER
    local DATASET_NAME OPTS

    for DATASET_NAME in ${DATASETS_ORDER[@]}; do
        OPTS=${DATASETS[$DATASET_NAME]}
        zfs create -v $OPTS $POOL/$DATASET_NAME
    done
}

function setup-EFI-system-partitions
{
    local NUM=${PARTITION_NUMBER[EFI]} D DEV DIR

    for D in ${DRIVES[@]}; do
        DEV=$D-part$NUM
        DIR=/mnt/boot/efis/${D##*/}-part$NUM
        mkfs.vfat -F 32 -n EFI $DEV
        mkdir -p $DIR
        mount -t vfat $DEV $DIR
    done
}

function disable-zpool-cache
{
    # Do not want the automatic importing that a ZFS pool cache file causes, and
    # do not want a cache file to be automatically created, so create an empty
    # dummy that is immutable.  My /etc/nixos/configuration.nix handles mounting
    # the datasets itself, and it links to the dummy cache file in /state/.

    local DIR=/mnt/state/etc/zfs
    local FILE=$DIR/zpool.cache

    mkdir -p $DIR
    rm -f $FILE
    touch $FILE
    chmod a-w $FILE
    chattr +i $FILE
}

function setup-state-dir
{
    # Create this before first boot, because my /etc/nixos/configuration.nix
    # needs to use it immediately.
    systemd-machine-id-setup --root=/mnt --print

    # The ZFS-on-root guide says this would be for "immutable root filesystem"
    # for "erasing all your darlings", but I'm not doing that.

    local X

    for X in /etc/{nixos,cryptkey.d}; do
        mkdir -p /mnt/state/$X /mnt/$X
        mount -o bind /mnt/state/$X /mnt/$X
    done
}

function setup-etc-nixos-git-repo
{
    local PERHOST=/mnt/etc/nixos/per-host/$INST_NAME

    cp -d -R -T "$SELF_REPO" /mnt/etc/nixos

    mkdir -p $PERHOST
    nixos-generate-config --no-filesystems --dir $PERHOST
    rm $PERHOST/configuration.nix  # Not needed with my repo.
}

function suspend-until-resume
{
    local MSG="${1:+ }${1:- }${1:+ }"

    echo -e '\nSuspending.' "When${MSG}ready," 'you must resume this script, e.g. by using `fg`.'
    suspend
}

function suspend-until-post-config-resume
{
    local VM_ZVOL_IDS=()
    for I in "${!EXTRA_DATASETS[@]}"; do
        if [[ "$I" =~ ^VMs/blkdev/([[:digit:]]+)$ ]]; then
            VM_ZVOL_IDS+=("${BASH_REMATCH[1]}")
        fi
    done
    VM_ZVOL_IDS=( $(IFS=$'\n'; sort -n <<<"${VM_ZVOL_IDS[*]}") )

    cat <<EOF

Now you must setup /mnt/etc/nixos/per-host/$INST_NAME/default.nix et al
to correspond to this new install:

  my.hostName = "$INST_NAME";
  my.zfs = {
    mirrorDrives = [
$(for D in "${DRIVES[@]}"; do
    echo "      \"$(basename "$D")\""
  done)
    ];
    partitions = {
$(for P in legacyBIOS EFI boot main swap; do
    printf "      %-10s = %s;\n" $P ${PARTITION_NUMBER[$P]}
  done)
    };
    pools = let id = "$INST_ID"; in {
      boot.name = "boot-\${id}";
      main.name = "main-\${id}";
    };
    usersZvolsForVMs = [
$(for N in "${VM_ZVOL_IDS[@]}"; do
    echo "      { id = \"$N\"; owner = \"\${TODO}\"; }"
  done)
    ];
  };

EOF
    fdisk -x ${DRIVES[@]}
    echo
    zfs list

    suspend-until-resume "the new config is"
}

function resume-check-still-desired
{
    # Allow the user to choose to abort at this point, and clean-up if aborting.

    REPLY=""
    while [ "$REPLY" != yes ] && [ "$REPLY" != no ]; do
        read -p "Continue with installation? "
    done

    if [ no == "$REPLY" ]; then
        # First, destroy the pools we'd created, to prevent them from possibly
        # being seen again by any other later zpool commands if blkdiscard
        # cannot be done on these drives (e.g. in some VMs) and some other
        # partitions are later created that happen to have the same location(s).
        # Then, destroy the partitions we'd created.
        clean-up destroy
        zap-discard-drives
        exit
    fi
}

function do-in-new-system
{
    nixos-enter --silent --root /mnt -- "$@"
}

function setup-channels
{
    case $1 in
        (installer) local DO="" ;;
        (new)       local DO=do-in-new-system ;;
        (*) exit 2 ;;
    esac

    # Add and update the nixos-unstable channel because my
    # /etc/nixos/configuration.nix uses it, and doing nixos-install needs this,
    # and the new system will need this.
    #
    # (Note: The nixos channel is not updated, so that it remains at the
    # revision provided by the installer system, so that it is the user that
    # chooses which revision of the installer system to install from and chooses
    # when to update the channels in the new system.)

    $DO nix-channel --add "$CHANNEL_NIXOS_UNSTABLE" nixos-unstable
    case $1 in
        (installer) $DO nix-channel --update nixos-unstable ;;
        (new)       ;; # Unnecessary and would encounter an error.
    esac

    $DO nix-channel --add "$CHANNEL_OXALICA_RUST_OVERLAY" oxalica-rust-overlay
    case $1 in
        (installer) $DO nix-channel --update oxalica-rust-overlay ;;
        (new)       ;; # Unnecessary and would encounter an error.
    esac
}

function snapshot
{
    local NAME=$1 POOL

    for POOL in ${POOL_NAME[@]}; do
        zfs snapshot -r $POOL@$NAME
    done
}

function clean-up
{
    local ZCMD=$1

    [ $ZCMD == export ] || [ $ZCMD == destroy ]

    # (This order matters because the preceeding are mounted on the succeeding.)
    umount /mnt/boot/efis/*
    zpool $ZCMD ${POOL_NAME[boot]}
    zpool $ZCMD ${POOL_NAME[main]}
}


# Operations

function create-pools
{
    create-boot-pool
    create-main-pool
}

function create-datasets
{
    # Do main first so that mountpoints for the boot pool are created in main pool.
    create-sub-datasets ${POOL_NAME[main]} MAIN_DATASETS
    create-sub-datasets ${POOL_NAME[main]} EXTRA_DATASETS
    create-sub-datasets ${POOL_NAME[boot]} BOOT_DATASETS
}

function create-zfs
{
    zap-discard-drives
    partition-drives
    create-pools
    create-datasets
    setup-EFI-system-partitions
    disable-zpool-cache
}

function create-nixos-config
{
    setup-state-dir
    setup-etc-nixos-git-repo
    suspend-until-post-config-resume
    resume-check-still-desired
}

function install-nixos
{
    # Download the nixos-unstable and oxalica-rust-overlay additional channels
    # into the installer system, to make them available to the next command.
    setup-channels installer

    # By using --channel, the additional channels are also (together
    # with the nixos channel) copied from the installer system into
    # the installee system.
    nixos-install --root /mnt --channel /nix/var/nix/profiles/per-user/root/channels \
                  --verbose --show-trace --cores 0 --max-jobs 8

    # Register the additional channels in the installee system, but
    # do not attempt to download them into there.  The previous command
    # already copied them, and attempting to update the channels via
    # nixos-enter would encounter an error (due to nix build
    # sandboxing not working in a chroot, I suspected).
    setup-channels new
}

function suspend-after-install
{
    suspend-until-resume
    resume-check-still-desired
}

create-zfs
create-nixos-config
snapshot pre-install
install-nixos
snapshot post-install
if [ ${SUSPEND_AFTER_INSTALL:-} ]; then suspend-after-install; fi
clean-up export

echo "
Now you may reboot into the newly installed system.
"
